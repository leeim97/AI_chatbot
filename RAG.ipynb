{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255ff2e5-7513-4c2a-a404-fffbf96a30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "client = OpenAI(api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1cbb47-8545-4dcf-a226-771d11d6b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_url(url):\n",
    "    return 'https://drive.google.com/uc?id='+url.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa27a767-fcfc-4e3c-9036-59c4c7238fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.2.12)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (0.1.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.12->langchain)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (2.1)\n",
      "Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: packaging\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "Successfully installed packaging-24.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42975aef-8296-45b6-bd2f-9f5ed2ed6aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0.post1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.1)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Collecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached faiss_cpu-1.8.0.post1-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.2 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.2 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.2 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, intel-openmp, safetensors, mkl, faiss-cpu, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed faiss-cpu-1.8.0.post1 huggingface-hub-0.23.4 intel-openmp-2021.4.0 mkl-2021.4.0 safetensors-0.4.3 sentence-transformers-3.0.1 tbb-2021.13.0 tokenizers-0.19.1 torch-2.3.1 transformers-4.42.3\n"
     ]
    }
   ],
   "source": [
    "# FAISS(벡터스토어) 모듈 다운\n",
    "!pip install faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8711840-c101-46e8-88cf-6c1de9102df7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.7)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (0.2.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (1.10.12)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369a9c4a-5ef0-4fe7-89cd-89a1e490b07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-openai) (0.2.12)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-openai) (1.35.10)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.84)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.10.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\samsung\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.32.0->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.14-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 41.0/45.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 kB 759.5 kB/s eta 0:00:00\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/799.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 61.4/799.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 256.0/799.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 471.0/799.0 kB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 634.9/799.0 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/799.0 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 799.0/799.0 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.1.14 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2e8435-5c1e-4b94-bf13-28b90b73fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c929bb4d-2bba-40b1-8a0f-31efc0ff9e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\programdata\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.42.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\programdata\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# huggingFaceEmbeddings 다운\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d19d636-daab-40cc-8615-cc78ffb41998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184991\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='data/simple.csv', encoding='utf-8')\n",
    "data = loader.load()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58262c8-2e29-4d8d-8271-310bbd5b554c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    encoding_name='cl100k_base'\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(data)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53dd8146-aab7-42a4-a7fc-ffd75a16f200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/simple.csv', 'row': 100}, page_content=': 100\\n요리명: 소세지크로와상\\n재료: [재료] 강력분 360g| 박력분 90g| 물 200g| 드라이 이스트 11g| 소금 9g| 설탕 67g| 버터 45g| 탈지분유 13g| 달걀 1개| 충전용 버터 350g| 달걀 물 약간')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a896b0-bfc4-4fb3-8fe9-6e969f5f8730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe19de-925e-4ac3-91d2-fff1e32a9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = FAISS.from_documents(documents,\n",
    "#                                    embedding = embeddings_model,\n",
    "#                                    distance_strategy = DistanceStrategy.COSINE  \n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "727856b7-4005-4d0e-bc6f-c13a9f04cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save db\n",
    "# vectorstore.save_local('./db/faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f6254a-ce10-43e4-98f2-a2f271ff4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load db\n",
    "vectorstore = FAISS.load_local('./db/faiss', embeddings_model,\n",
    "                     allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4725b2-f956-4893-b976-028ab4599d51",
   "metadata": {},
   "source": [
    "## 교차반응 임베딩, 벡터스토어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be37aed7-7fd4-445d-952c-cfbdeb29bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader2 = CSVLoader(file_path='data/교차반응식품.csv', encoding='utf-8')\n",
    "data2 = loader.load()\n",
    "# for i in range(len(data)):\n",
    "#     print(len(data[i].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5438b61d-c732-4c62-b1c1-5361173e3771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184995"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter2 = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=38,\n",
    "    chunk_overlap=3,\n",
    "    encoding_name='cl100k_base'\n",
    ")\n",
    "\n",
    "documents2 = text_splitter.split_documents(data2)\n",
    "len(documents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7160e13a-e496-475a-94eb-dfc35acae790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model2 = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec8db0a-0b96-4bb2-a511-c2c130941c28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vectorstore2 \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents2,\n\u001b[0;32m      2\u001b[0m                                    embedding \u001b[38;5;241m=\u001b[39m embeddings_model2,\n\u001b[0;32m      3\u001b[0m                                    distance_strategy \u001b[38;5;241m=\u001b[39m DistanceStrategy\u001b[38;5;241m.\u001b[39mCOSINE  \n\u001b[0;32m      4\u001b[0m                                   )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:989\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    987\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    988\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:930\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    911\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m    932\u001b[0m         texts,\n\u001b[0;32m    933\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    938\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:105\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    103\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mencode(\n\u001b[0;32m    106\u001b[0m         texts, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_kwargs\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:517\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[0;32m    514\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 517\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(features)\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    519\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1142\u001b[0m     embedding_output,\n\u001b[0;32m   1143\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1144\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1145\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1146\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1148\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1149\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1150\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1151\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1152\u001b[0m )\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    695\u001b[0m         hidden_states,\n\u001b[0;32m    696\u001b[0m         attention_mask,\n\u001b[0;32m    697\u001b[0m         layer_head_mask,\n\u001b[0;32m    698\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    699\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    700\u001b[0m         past_key_value,\n\u001b[0;32m    701\u001b[0m         output_attentions,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    628\u001b[0m )\n\u001b[0;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorstore2 = FAISS.from_documents(documents2,\n",
    "                                   embedding = embeddings_model2,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE  \n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ff613550-17e6-47a1-89b7-b2d41295ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save db\n",
    "vectorstore2.save_local('./db/faiss2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9927ab3-d6d7-4bab-a74a-58ac60f061ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "# load db\n",
    "vectorstore2 = FAISS.load_local('./db/faiss2', embeddings_model2,\n",
    "                     allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "492cf9a4-30b4-406a-8ac0-a664bc30b411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2769dff5b90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640115f-a184-4777-bc75-1eba4c2bea0f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91fcd0f-7ecd-4bd2-a4b9-e1337db33b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef6e8fe6-709d-49dd-a90b-703eb056e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/만개의레시피Raw.csv', encoding='cp949', encoding_errors='ignore')\n",
    "df.to_csv('data/recipe_utf8.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "339e5467-261f-4e96-a464-63a3eab9a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/recipe_utf8.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8dcaafa5-b33f-4541-91e4-28dbbb1e27e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RCP_SNO</th>\n",
       "      <th>RCP_TTL</th>\n",
       "      <th>CKG_NM</th>\n",
       "      <th>RGTR_ID</th>\n",
       "      <th>RGTR_NM</th>\n",
       "      <th>INQ_CNT</th>\n",
       "      <th>RCMM_CNT</th>\n",
       "      <th>SRAP_CNT</th>\n",
       "      <th>CKG_MTH_ACTO_NM</th>\n",
       "      <th>CKG_STA_ACTO_NM</th>\n",
       "      <th>CKG_MTRL_ACTO_NM</th>\n",
       "      <th>CKG_KND_ACTO_NM</th>\n",
       "      <th>CKG_IPDC</th>\n",
       "      <th>CKG_MTRL_CN</th>\n",
       "      <th>CKG_INBUN_NM</th>\n",
       "      <th>CKG_DODF_NM</th>\n",
       "      <th>CKG_TIME_NM</th>\n",
       "      <th>FIRST_REG_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128671</td>\n",
       "      <td>어묵김말이</td>\n",
       "      <td>어묵김말이</td>\n",
       "      <td>skfo0701</td>\n",
       "      <td>꽃날</td>\n",
       "      <td>10072</td>\n",
       "      <td>6</td>\n",
       "      <td>66</td>\n",
       "      <td>튀김</td>\n",
       "      <td>간식</td>\n",
       "      <td>가공식품류</td>\n",
       "      <td>디저트</td>\n",
       "      <td>맛있는 김말이에 쫄깃함을 더한 어묵 김말이예요-</td>\n",
       "      <td>[재료] 어묵 2개| 김밥용김 3장| 당면 1움큼| 양파 1/2개| 당근 1/2개|...</td>\n",
       "      <td>2인분</td>\n",
       "      <td>초급</td>\n",
       "      <td>60분이내</td>\n",
       "      <td>20070402131403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128892</td>\n",
       "      <td>두부에 꼬리가 달렸어요!!</td>\n",
       "      <td>두부새우전</td>\n",
       "      <td>skfo0701</td>\n",
       "      <td>꽃날</td>\n",
       "      <td>5817</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>부침</td>\n",
       "      <td>일상</td>\n",
       "      <td>해물류</td>\n",
       "      <td>밑반찬</td>\n",
       "      <td>꼬리가 너-무- 매력적인 두부새우전. 두부와 야채를 한번에!! 영양까지 만점인 두부...</td>\n",
       "      <td>[재료] 두부 1/2모| 당근 1/2개| 고추 2개| 브로콜리 1/4개| 새우 4마...</td>\n",
       "      <td>3인분</td>\n",
       "      <td>초급</td>\n",
       "      <td>30분이내</td>\n",
       "      <td>20070402205937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128932</td>\n",
       "      <td>입안에서 톡톡톡</td>\n",
       "      <td>알밥</td>\n",
       "      <td>skfo0701</td>\n",
       "      <td>꽃날</td>\n",
       "      <td>6975</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>굽기</td>\n",
       "      <td>일상</td>\n",
       "      <td>해물류</td>\n",
       "      <td>밥/죽/떡</td>\n",
       "      <td>간단하게 만들어 보는 알이 톡톡톡 알밥♥ 다 먹고 누룽지까지 싹싹 긁어먹는게 최고죠...</td>\n",
       "      <td>[재료] 밥 1+1/2공기| 당근 1/4개| 치자단무지 1/2개| 신김치 1쪽| 무...</td>\n",
       "      <td>2인분</td>\n",
       "      <td>초급</td>\n",
       "      <td>30분이내</td>\n",
       "      <td>20070402224355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131871</td>\n",
       "      <td>★현미호두죽</td>\n",
       "      <td>현미호두죽</td>\n",
       "      <td>cds1117</td>\n",
       "      <td>햇님&amp;별님</td>\n",
       "      <td>3339</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>끓이기</td>\n",
       "      <td>일상</td>\n",
       "      <td>쌀</td>\n",
       "      <td>밥/죽/떡</td>\n",
       "      <td>현미호두죽</td>\n",
       "      <td>[재료] 현미 4컵| 찹쌀 2컵| 호두 50g| 물 1/2컵| 소금 약간</td>\n",
       "      <td>2인분</td>\n",
       "      <td>초급</td>\n",
       "      <td>30분이내</td>\n",
       "      <td>20070410142301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139247</td>\n",
       "      <td>부들부들 보들보들 북어갈비♥</td>\n",
       "      <td>북어갈비</td>\n",
       "      <td>skfo0701</td>\n",
       "      <td>꽃날</td>\n",
       "      <td>7173</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>굽기</td>\n",
       "      <td>술안주</td>\n",
       "      <td>건어물류</td>\n",
       "      <td>메인반찬</td>\n",
       "      <td>오늘은 집에서 굴러다니고 쉽게 구할 수 있는 북어로 일품요리를 만들어 보았어요! 도...</td>\n",
       "      <td>[재료] 북어포 1마리| 찹쌀가루 1C [양념] 간장 2T| 설탕 1T| 물 1T|...</td>\n",
       "      <td>2인분</td>\n",
       "      <td>초급</td>\n",
       "      <td>60분이내</td>\n",
       "      <td>20070501000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184986</th>\n",
       "      <td>7014703</td>\n",
       "      <td>맛 보장 명란젓 크림스파게티</td>\n",
       "      <td>명란젓크림스파게티</td>\n",
       "      <td>45205520</td>\n",
       "      <td>피오르디쿠치나</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>기타</td>\n",
       "      <td>손님접대</td>\n",
       "      <td>해물류</td>\n",
       "      <td>양식</td>\n",
       "      <td>이탈리아 사람들은 크림 파스타를 안 먹지만 제가 먹고 싶어서 만들어본 명란젓 크림 ...</td>\n",
       "      <td>[재료] 올리브오일| 스파게티면 80g| 명란젓 1덩이| 생크림 100g| 마늘 1...</td>\n",
       "      <td>1인분</td>\n",
       "      <td>아무나</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20231130211113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184987</th>\n",
       "      <td>7014704</td>\n",
       "      <td>특별하고 맛있는 아마트리치아나 스파게티</td>\n",
       "      <td>아마트리치아나스파게티</td>\n",
       "      <td>45205520</td>\n",
       "      <td>피오르디쿠치나</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>기타</td>\n",
       "      <td>손님접대</td>\n",
       "      <td>돼지고기</td>\n",
       "      <td>양식</td>\n",
       "      <td>이 파스타가 먹고 싶었는데 관찰레를 구하기가 쉽지 않아 베이컨이나 판체타로 해보았는...</td>\n",
       "      <td>[재료] 올리브오일| 스파게티면 280~300g| 관찰레 120g| 홀토마토 1캔|...</td>\n",
       "      <td>4인분</td>\n",
       "      <td>아무나</td>\n",
       "      <td>30분이내</td>\n",
       "      <td>20231130212952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184988</th>\n",
       "      <td>7014705</td>\n",
       "      <td>오징어젓무침 만드는법~밥도둑 짜지않은 젓갈무침 만들기 ~</td>\n",
       "      <td>오징어젓무침</td>\n",
       "      <td>mimi030630</td>\n",
       "      <td>노란장미</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>무침</td>\n",
       "      <td>일상</td>\n",
       "      <td>가공식품류</td>\n",
       "      <td>김치/젓갈/장류</td>\n",
       "      <td>밥도둑 젓갈무침 맛나게 먹구선 짜게 먹게돼 물 많이 먹게되는 젓갈무침 좋아하지만 절...</td>\n",
       "      <td>[재료] 오징어젓200g| 무말랭이15g| 청양고추2개| 홍고추1개| 오이고추1개|...</td>\n",
       "      <td>2인분</td>\n",
       "      <td>아무나</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20231130213249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184989</th>\n",
       "      <td>7014706</td>\n",
       "      <td>급식 계란찜 중탕 만들기</td>\n",
       "      <td>계란찜</td>\n",
       "      <td>ryuyi1220</td>\n",
       "      <td>해피레시피류이</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>찜</td>\n",
       "      <td>일상</td>\n",
       "      <td>달걀/유제품</td>\n",
       "      <td>밑반찬</td>\n",
       "      <td>안녕하세요  네이버 푸드인플루언서 류이입니다~^^ 중1 장남이를 176cm 진격의 ...</td>\n",
       "      <td>[재료] 달걀 6개| 우유 200ml| 물 100ml| 맛살 3개| 당근 1/3개|...</td>\n",
       "      <td>3인분</td>\n",
       "      <td>아무나</td>\n",
       "      <td>30분이내</td>\n",
       "      <td>20231130222955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184990</th>\n",
       "      <td>7014707</td>\n",
       "      <td>전자레인지 계란찜 만드는법</td>\n",
       "      <td>계란찜</td>\n",
       "      <td>mimi030630</td>\n",
       "      <td>노란장미</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>찜</td>\n",
       "      <td>일상</td>\n",
       "      <td>달걀/유제품</td>\n",
       "      <td>밑반찬</td>\n",
       "      <td>전자레인지 계란찜 만드는법</td>\n",
       "      <td>[재료] 계란 4개| 물 동량 250cc| 참치액 1T| 쪽파 조금| 알새우 1/2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>아무나</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20231130235050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184991 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RCP_SNO                          RCP_TTL       CKG_NM     RGTR_ID  \\\n",
       "0        128671                            어묵김말이        어묵김말이    skfo0701   \n",
       "1        128892                  두부에 꼬리가 달렸어요!!         두부새우전    skfo0701   \n",
       "2        128932                        입안에서 톡톡톡            알밥    skfo0701   \n",
       "3        131871                           ★현미호두죽        현미호두죽     cds1117   \n",
       "4        139247                  부들부들 보들보들 북어갈비♥         북어갈비    skfo0701   \n",
       "...         ...                              ...          ...         ...   \n",
       "184986  7014703                  맛 보장 명란젓 크림스파게티    명란젓크림스파게티    45205520   \n",
       "184987  7014704            특별하고 맛있는 아마트리치아나 스파게티  아마트리치아나스파게티    45205520   \n",
       "184988  7014705  오징어젓무침 만드는법~밥도둑 짜지않은 젓갈무침 만들기 ~       오징어젓무침  mimi030630   \n",
       "184989  7014706                    급식 계란찜 중탕 만들기          계란찜   ryuyi1220   \n",
       "184990  7014707                   전자레인지 계란찜 만드는법          계란찜  mimi030630   \n",
       "\n",
       "        RGTR_NM  INQ_CNT  RCMM_CNT  SRAP_CNT CKG_MTH_ACTO_NM CKG_STA_ACTO_NM  \\\n",
       "0            꽃날    10072         6        66              튀김              간식   \n",
       "1            꽃날     5817         3        27              부침              일상   \n",
       "2            꽃날     6975         8        36              굽기              일상   \n",
       "3         햇님&별님     3339         0        11             끓이기              일상   \n",
       "4            꽃날     7173         3        97              굽기             술안주   \n",
       "...         ...      ...       ...       ...             ...             ...   \n",
       "184986  피오르디쿠치나       59         0         0              기타            손님접대   \n",
       "184987  피오르디쿠치나       46         0         0              기타            손님접대   \n",
       "184988     노란장미      110         0         8              무침              일상   \n",
       "184989  해피레시피류이      170         0         6               찜              일상   \n",
       "184990     노란장미      763         0        11               찜              일상   \n",
       "\n",
       "       CKG_MTRL_ACTO_NM CKG_KND_ACTO_NM  \\\n",
       "0                 가공식품류             디저트   \n",
       "1                   해물류             밑반찬   \n",
       "2                   해물류           밥/죽/떡   \n",
       "3                     쌀           밥/죽/떡   \n",
       "4                  건어물류            메인반찬   \n",
       "...                 ...             ...   \n",
       "184986              해물류              양식   \n",
       "184987             돼지고기              양식   \n",
       "184988            가공식품류        김치/젓갈/장류   \n",
       "184989           달걀/유제품             밑반찬   \n",
       "184990           달걀/유제품             밑반찬   \n",
       "\n",
       "                                                 CKG_IPDC  \\\n",
       "0                              맛있는 김말이에 쫄깃함을 더한 어묵 김말이예요-   \n",
       "1       꼬리가 너-무- 매력적인 두부새우전. 두부와 야채를 한번에!! 영양까지 만점인 두부...   \n",
       "2       간단하게 만들어 보는 알이 톡톡톡 알밥♥ 다 먹고 누룽지까지 싹싹 긁어먹는게 최고죠...   \n",
       "3                                                   현미호두죽   \n",
       "4       오늘은 집에서 굴러다니고 쉽게 구할 수 있는 북어로 일품요리를 만들어 보았어요! 도...   \n",
       "...                                                   ...   \n",
       "184986  이탈리아 사람들은 크림 파스타를 안 먹지만 제가 먹고 싶어서 만들어본 명란젓 크림 ...   \n",
       "184987  이 파스타가 먹고 싶었는데 관찰레를 구하기가 쉽지 않아 베이컨이나 판체타로 해보았는...   \n",
       "184988  밥도둑 젓갈무침 맛나게 먹구선 짜게 먹게돼 물 많이 먹게되는 젓갈무침 좋아하지만 절...   \n",
       "184989  안녕하세요  네이버 푸드인플루언서 류이입니다~^^ 중1 장남이를 176cm 진격의 ...   \n",
       "184990                                     전자레인지 계란찜 만드는법   \n",
       "\n",
       "                                              CKG_MTRL_CN CKG_INBUN_NM  \\\n",
       "0       [재료] 어묵 2개| 김밥용김 3장| 당면 1움큼| 양파 1/2개| 당근 1/2개|...          2인분   \n",
       "1       [재료] 두부 1/2모| 당근 1/2개| 고추 2개| 브로콜리 1/4개| 새우 4마...          3인분   \n",
       "2       [재료] 밥 1+1/2공기| 당근 1/4개| 치자단무지 1/2개| 신김치 1쪽| 무...          2인분   \n",
       "3                [재료] 현미 4컵| 찹쌀 2컵| 호두 50g| 물 1/2컵| 소금 약간          2인분   \n",
       "4       [재료] 북어포 1마리| 찹쌀가루 1C [양념] 간장 2T| 설탕 1T| 물 1T|...          2인분   \n",
       "...                                                   ...          ...   \n",
       "184986  [재료] 올리브오일| 스파게티면 80g| 명란젓 1덩이| 생크림 100g| 마늘 1...          1인분   \n",
       "184987  [재료] 올리브오일| 스파게티면 280~300g| 관찰레 120g| 홀토마토 1캔|...          4인분   \n",
       "184988  [재료] 오징어젓200g| 무말랭이15g| 청양고추2개| 홍고추1개| 오이고추1개|...          2인분   \n",
       "184989  [재료] 달걀 6개| 우유 200ml| 물 100ml| 맛살 3개| 당근 1/3개|...          3인분   \n",
       "184990  [재료] 계란 4개| 물 동량 250cc| 참치액 1T| 쪽파 조금| 알새우 1/2...          NaN   \n",
       "\n",
       "       CKG_DODF_NM CKG_TIME_NM    FIRST_REG_DT  \n",
       "0               초급       60분이내  20070402131403  \n",
       "1               초급       30분이내  20070402205937  \n",
       "2               초급       30분이내  20070402224355  \n",
       "3               초급       30분이내  20070410142301  \n",
       "4               초급       60분이내  20070501000844  \n",
       "...            ...         ...             ...  \n",
       "184986         아무나         NaN  20231130211113  \n",
       "184987         아무나       30분이내  20231130212952  \n",
       "184988         아무나         NaN  20231130213249  \n",
       "184989         아무나       30분이내  20231130222955  \n",
       "184990         아무나         NaN  20231130235050  \n",
       "\n",
       "[184991 rows x 18 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/만개의레시피Raw.csv', encoding='cp949', encoding_errors='ignore')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7fe8388e-c726-4f0a-8928-cafd9fc4b727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CKG_NM</th>\n",
       "      <th>CKG_MTRL_CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>어묵김말이</td>\n",
       "      <td>[재료] 어묵 2개| 김밥용김 3장| 당면 1움큼| 양파 1/2개| 당근 1/2개|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>두부새우전</td>\n",
       "      <td>[재료] 두부 1/2모| 당근 1/2개| 고추 2개| 브로콜리 1/4개| 새우 4마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>알밥</td>\n",
       "      <td>[재료] 밥 1+1/2공기| 당근 1/4개| 치자단무지 1/2개| 신김치 1쪽| 무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>현미호두죽</td>\n",
       "      <td>[재료] 현미 4컵| 찹쌀 2컵| 호두 50g| 물 1/2컵| 소금 약간</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>북어갈비</td>\n",
       "      <td>[재료] 북어포 1마리| 찹쌀가루 1C [양념] 간장 2T| 설탕 1T| 물 1T|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184986</th>\n",
       "      <td>명란젓크림스파게티</td>\n",
       "      <td>[재료] 올리브오일| 스파게티면 80g| 명란젓 1덩이| 생크림 100g| 마늘 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184987</th>\n",
       "      <td>아마트리치아나스파게티</td>\n",
       "      <td>[재료] 올리브오일| 스파게티면 280~300g| 관찰레 120g| 홀토마토 1캔|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184988</th>\n",
       "      <td>오징어젓무침</td>\n",
       "      <td>[재료] 오징어젓200g| 무말랭이15g| 청양고추2개| 홍고추1개| 오이고추1개|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184989</th>\n",
       "      <td>계란찜</td>\n",
       "      <td>[재료] 달걀 6개| 우유 200ml| 물 100ml| 맛살 3개| 당근 1/3개|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184990</th>\n",
       "      <td>계란찜</td>\n",
       "      <td>[재료] 계란 4개| 물 동량 250cc| 참치액 1T| 쪽파 조금| 알새우 1/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CKG_NM                                        CKG_MTRL_CN\n",
       "0             어묵김말이  [재료] 어묵 2개| 김밥용김 3장| 당면 1움큼| 양파 1/2개| 당근 1/2개|...\n",
       "1             두부새우전  [재료] 두부 1/2모| 당근 1/2개| 고추 2개| 브로콜리 1/4개| 새우 4마...\n",
       "2                알밥  [재료] 밥 1+1/2공기| 당근 1/4개| 치자단무지 1/2개| 신김치 1쪽| 무...\n",
       "3             현미호두죽           [재료] 현미 4컵| 찹쌀 2컵| 호두 50g| 물 1/2컵| 소금 약간\n",
       "4              북어갈비  [재료] 북어포 1마리| 찹쌀가루 1C [양념] 간장 2T| 설탕 1T| 물 1T|...\n",
       "...             ...                                                ...\n",
       "184986    명란젓크림스파게티  [재료] 올리브오일| 스파게티면 80g| 명란젓 1덩이| 생크림 100g| 마늘 1...\n",
       "184987  아마트리치아나스파게티  [재료] 올리브오일| 스파게티면 280~300g| 관찰레 120g| 홀토마토 1캔|...\n",
       "184988       오징어젓무침  [재료] 오징어젓200g| 무말랭이15g| 청양고추2개| 홍고추1개| 오이고추1개|...\n",
       "184989          계란찜  [재료] 달걀 6개| 우유 200ml| 물 100ml| 맛살 3개| 당근 1/3개|...\n",
       "184990          계란찜  [재료] 계란 4개| 물 동량 250cc| 참치액 1T| 쪽파 조금| 알새우 1/2...\n",
       "\n",
       "[184991 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1  = df.loc[:,['CKG_NM','CKG_MTRL_CN']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55127572-fc63-4a27-8c1c-d3e36bfd45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'CKG_NM':'요리명','CKG_MTRL_CN':'재료'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b157b288-5877-4730-8890-f022b90e3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={'CKG_NM':'요리명','CKG_MTRL_CN':'재료'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6da03274-ba14-4d9d-a7fa-1ca74e1c9a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>요리명</th>\n",
       "      <th>재료</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32410</th>\n",
       "      <td></td>\n",
       "      <td>[재료] 계란 4개| 배추김치 조금| 양파 1/2개| 표고버섯 1줌| 오징어 1마리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119327</th>\n",
       "      <td>불고기숙주볶음</td>\n",
       "      <td>[주 재료] 숙주 120~150g| 새송이 버섯 50~60g| 양파 1/4개| 불고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113858</th>\n",
       "      <td>소고기무국</td>\n",
       "      <td>[재료] 소고기 사태 2근| 두부 1모| 대파 2줄기| 황태채 1/2C| 다시마| ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27025</th>\n",
       "      <td>야채볼</td>\n",
       "      <td>[재료] 연어 60g| 낫토 45g| 계란노른자| 치커리| 김| 밥 [양념] 식초 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174631</th>\n",
       "      <td>오이지</td>\n",
       "      <td>[재료] 백오이 10개| 청양고추 3개| 굵은소금 1컵| 식초 1컵| 설탕 1/2컵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110773</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[재료] 생일케잌| 미역국| 두부 카프레제| 연어 스시볼| 연어 샐러드| 갈비찜| ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115582</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[재료] 달걀| 고구마| 단호박| 라면| 떡볶이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124331</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[재료] 중화펜 1 [양념] 돼지기름 1국자| 식용유 1국자</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184991 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             요리명                                                 재료\n",
       "32410             [재료] 계란 4개| 배추김치 조금| 양파 1/2개| 표고버섯 1줌| 오징어 1마리...\n",
       "119327   불고기숙주볶음  [주 재료] 숙주 120~150g| 새송이 버섯 50~60g| 양파 1/4개| 불고...\n",
       "113858     소고기무국  [재료] 소고기 사태 2근| 두부 1모| 대파 2줄기| 황태채 1/2C| 다시마| ...\n",
       "27025        야채볼  [재료] 연어 60g| 낫토 45g| 계란노른자| 치커리| 김| 밥 [양념] 식초 ...\n",
       "174631       오이지  [재료] 백오이 10개| 청양고추 3개| 굵은소금 1컵| 식초 1컵| 설탕 1/2컵...\n",
       "...          ...                                                ...\n",
       "110773       NaN  [재료] 생일케잌| 미역국| 두부 카프레제| 연어 스시볼| 연어 샐러드| 갈비찜| ...\n",
       "115582       NaN                         [재료] 달걀| 고구마| 단호박| 라면| 떡볶이\n",
       "117515       NaN                                                NaN\n",
       "122334       NaN                                                NaN\n",
       "124331       NaN                  [재료] 중화펜 1 [양념] 돼지기름 1국자| 식용유 1국자\n",
       "\n",
       "[184991 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sort_values(by='요리명',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f663f9c8-7d48-4da9-9294-a3abcd78d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('data/simple.csv', index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbe501c-9575-4c04-9e18-ed84d46ea37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_d = {\n",
    "    '난류': ['우유', '참깨'],\n",
    "    '소고기': ['닭고기', '돼지고기'],\n",
    "    '돼지고기': ['닭고기', '소고기'],\n",
    "    '닭고기': ['돼지고기', '소고기'],\n",
    "    '새우': ['꽃게', '바닷가재'],\n",
    "    '게': ['굴', '새우', '오징어'],\n",
    "    '오징어': ['전복', '송이버섯'],\n",
    "    '고등어': ['연어', '전복'],\n",
    "    '조개류': ['새우', '게', '굴', '오징어'],\n",
    "    '우유': ['돼지고기', '염소젖', '말젖'],\n",
    "    '땅콩': ['완두콩', '렌즈콩', '대두'],\n",
    "    '호두': ['브라질너트', '캐슈넛', '헤이즐넛'],\n",
    "    '잣': ['호두', '아몬드'],\n",
    "    '대두': ['땅콩', '녹두', '강낭콩'],\n",
    "    '복숭아': ['사과', '자두', '체리', '배'],\n",
    "    '토마토': ['땅콩', '호밀풀', '사과', '샐러리', '쑥', '감자'],\n",
    "    '밀': ['호밀', '보리'],\n",
    "    '메밀': ['참깨', '밀'],\n",
    "    '아황산류': ['건포도', '백포도주']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f019f762-4fb1-4275-a104-ff9bd938b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'난류':['우유,참깨'],\n",
      "'소고기':['닭고기,돼지고기'],\n",
      "'돼지고기':['닭고기,소고기'],\n",
      "'닭고기':['돼지고기,소고기'],\n",
      "'새우':['꽃게,바닷가재'],\n",
      "'게':['굴,새우,오징어'],\n",
      "'오징어':['전복,송이버섯'],\n",
      "'고등어':['연어,전복'],\n",
      "'조개류':['새우,게,굴,오징어'],\n",
      "'우유':['돼지고기,염소젖,말젖'],\n",
      "'땅콩':['완두콩,렌즈콩,대두'],\n",
      "'호두':['브라질너트,캐슈넛,헤이즐넛'],\n",
      "'잣':['호두,아몬드'],\n",
      "'대두':['땅콩,녹두,강낭콩'],\n",
      "'복숭아':['사과,자두,체리,배'],\n",
      "'토마토':['땅콩,호밀풀,사과,샐러리,쑥,감자'],\n",
      "'밀':['호밀,보리'],\n",
      "'메밀':['참깨,밀'],\n",
      "'아황산류':['건포도,백포도주'],\n"
     ]
    }
   ],
   "source": [
    "for i,(a,b) in enumerate(c_d.items()):\n",
    "    bb = [ba.join(',') for ba in b]\n",
    "    print(f'\\'{a}\\':[\\'{\",\".join(b)}\\'],')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee1624f-7cb0-405a-bc14-99bd59462c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'난류':'우유,참깨',\n",
      "'소고기':'닭고기,돼지고기',\n",
      "'돼지고기':'닭고기,소고기',\n",
      "'닭고기':'돼지고기,소고기',\n",
      "'새우':'꽃게,바닷가재',\n",
      "'게':'굴,새우,오징어',\n",
      "'오징어':'전복,송이버섯',\n",
      "'고등어':'연어,전복',\n",
      "'조개류':'새우,게,굴,오징어',\n",
      "'우유':'돼지고기,염소젖,말젖',\n",
      "'땅콩':'완두콩,렌즈콩,대두',\n",
      "'호두':'브라질너트,캐슈넛,헤이즐넛',\n",
      "'잣':'호두,아몬드',\n",
      "'대두':'땅콩,녹두,강낭콩',\n",
      "'복숭아':'사과,자두,체리,배',\n",
      "'토마토':'땅콩,호밀풀,사과,샐러리,쑥,감자',\n",
      "'밀':'호밀,보리',\n",
      "'메밀':'참깨,밀',\n",
      "'아황산류':'건포도,백포도주',\n"
     ]
    }
   ],
   "source": [
    "for i,(a,b) in enumerate(c_d.items()):\n",
    "    bb = [ba.join(',') for ba in b]\n",
    "    print(f'\\'{a}\\':\\'{\",\".join(b)}\\',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c03427-6683-41ad-a78f-899ba2bfedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data = {'난류':['우유,참깨'],\n",
    "'소고기':['닭고기,돼지고기'],\n",
    "'돼지고기':['닭고기,소고기'],\n",
    "'닭고기':['돼지고기,소고기'],\n",
    "'새우':['꽃게,바닷가재'],\n",
    "'게':['굴,새우,오징어'],\n",
    "'오징어':['전복,송이버섯'],\n",
    "'고등어':['연어,전복'],\n",
    "'조개류':['새우,게,굴,오징어'],\n",
    "'우유':['돼지고기,염소젖,말젖'],\n",
    "'땅콩':['완두콩,렌즈콩,대두'],\n",
    "'호두':['브라질너트,캐슈넛,헤이즐넛'],\n",
    "'잣':['호두,아몬드'],\n",
    "'대두':['땅콩,녹두,강낭콩'],\n",
    "'복숭아':['사과,자두,체리,배'],\n",
    "'토마토':['땅콩,호밀풀,사과,샐러리,쑥,감자'],\n",
    "'밀':['호밀,보리'],\n",
    "'메밀':['참깨,밀'],\n",
    "'아황산류':['건포도,백포도주']})\n",
    "df=df.T\n",
    "df2 = df.reset_index()\n",
    "df2\n",
    "df2 = df2.rename(columns={'index':'알레르기식품',0:'교차반응식품'})\n",
    "df2.to_csv('data/교차반응식품.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ee3052-a2c6-4e61-9361-92eb6c50bc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>알레르기식품</th>\n",
       "      <th>교차반응식품</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>난류</td>\n",
       "      <td>우유,참깨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>소고기</td>\n",
       "      <td>닭고기,돼지고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>돼지고기</td>\n",
       "      <td>닭고기,소고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>닭고기</td>\n",
       "      <td>돼지고기,소고기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>새우</td>\n",
       "      <td>꽃게,바닷가재</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>게</td>\n",
       "      <td>굴,새우,오징어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>오징어</td>\n",
       "      <td>전복,송이버섯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>고등어</td>\n",
       "      <td>연어,전복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>조개류</td>\n",
       "      <td>새우,게,굴,오징어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>우유</td>\n",
       "      <td>돼지고기,염소젖,말젖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>땅콩</td>\n",
       "      <td>완두콩,렌즈콩,대두</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>호두</td>\n",
       "      <td>브라질너트,캐슈넛,헤이즐넛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>잣</td>\n",
       "      <td>호두,아몬드</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>대두</td>\n",
       "      <td>땅콩,녹두,강낭콩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>복숭아</td>\n",
       "      <td>사과,자두,체리,배</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>토마토</td>\n",
       "      <td>땅콩,호밀풀,사과,샐러리,쑥,감자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>밀</td>\n",
       "      <td>호밀,보리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>메밀</td>\n",
       "      <td>참깨,밀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>아황산류</td>\n",
       "      <td>건포도,백포도주</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   알레르기식품              교차반응식품\n",
       "0      난류               우유,참깨\n",
       "1     소고기            닭고기,돼지고기\n",
       "2    돼지고기             닭고기,소고기\n",
       "3     닭고기            돼지고기,소고기\n",
       "4      새우             꽃게,바닷가재\n",
       "5       게            굴,새우,오징어\n",
       "6     오징어             전복,송이버섯\n",
       "7     고등어               연어,전복\n",
       "8     조개류          새우,게,굴,오징어\n",
       "9      우유         돼지고기,염소젖,말젖\n",
       "10     땅콩          완두콩,렌즈콩,대두\n",
       "11     호두      브라질너트,캐슈넛,헤이즐넛\n",
       "12      잣              호두,아몬드\n",
       "13     대두           땅콩,녹두,강낭콩\n",
       "14    복숭아          사과,자두,체리,배\n",
       "15    토마토  땅콩,호밀풀,사과,샐러리,쑥,감자\n",
       "16      밀               호밀,보리\n",
       "17     메밀                참깨,밀\n",
       "18   아황산류            건포도,백포도주"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/교차반응식품.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49752c-4ba4-481f-9017-37b4b5abdb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b52eae-d321-45dd-826b-d4de4e245319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fafb09-f126-4429-96b9-3eef3177f62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3694e2-ccd7-4d51-acf6-9d61ae034889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d71694-a07b-4105-9f6e-1b56b94979af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82116651-0941-43bd-a0e8-047f30f9eed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12c8b99-f745-40ab-a80e-03ed5b6f64cf",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a25906-91d2-42ed-936a-bebfdf962a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b59ce-b6ad-44d1-9ad6-5e10f22febfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dbe57-538b-4bc7-b2ae-3b369a1f8f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b141d4-3415-413f-92a7-a71b0296040f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a39c0-feea-41ce-b7e0-ef336025a104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ddbee-65e3-4d78-b538-a83067ef9baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff013f4-dfe0-417c-8f97-c5b1c9a0709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e6841-e5fb-4065-b23b-2271d2d55bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3b3e5-11c8-4d12-847d-9d924343e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1147c-d1d6-4c86-9dc6-ee1e97029127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10d069d-3861-4e13-a983-3f4f3b875a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58631960-98bf-473f-accd-b8490629a1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "게 알레르기가 있으므로 게를 사용하지 않는 요리 레시피를 찾아야 합니다. \n",
      "재료에 게가 없는 \"건빵튀김\" 레시피를 찾아보겠습니다.\n",
      "\n",
      "레시피 링크: https://www.10000recipe.com/recipe/150679\n",
      "\n",
      "이 레시피는 건빵, 코코넛오일, 소금으로 만드는 건빵튀김입니다. 건빵을 코코넛오일에 튀겨 고소한 맛을 내며 소금으로 간을 해줍니다. 게 알레르기가 있는 경우에도 안전하게 즐길 수 있는 요리입니다.\n"
     ]
    }
   ],
   "source": [
    "# Retrieval\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 20, 'fetch_k': 500,'lambda_mult': 0.1}\n",
    ")\n",
    "\n",
    "query = '닭고기 알레르기가 있어. 볶음밥 레시피 알려줘'\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Prompt\n",
    "template = '''In the context, there are the name of a dish and its ingredients.\n",
    "Based on the ingredients,\n",
    "find a recipe on https://www.10000recipe.com/ and you must explain the ingredients and the recipe.\n",
    "If there are any allergies, exclude the ingredients that cause the allergies.\n",
    "For example, if there is a chicken allergy, you should provide a recipe for a dish that does not contain chicken.\n",
    "Provide the explanation in Korean.\n",
    "Answer the question based on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({'context': (format_docs(docs)), 'question':query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c474a701-7f6a-489f-8083-54319e69c7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 돼지고기를 먹어도 된다면, https://www.10000recipe.com/ 에서 \"돼지고기 두부찜\" 레시피를 추천드립니다.\n",
      "\n",
      "이 레시피의 재료는 다음과 같습니다:\n",
      "- 돼지고기 (삼겹살 또는 목살)\n",
      "- 두부\n",
      "- 대파\n",
      "- 마늘\n",
      "- 간장\n",
      "- 설탕\n",
      "- 참기름\n",
      "- 후추\n",
      "\n",
      "이 요리는 두부와 돼지고기를 함께 찌고 간장, 설탕, 마늘, 대파 등을 넣어 맛을 낸 후 마무리로 참기름과 후추를 뿌려 완성합니다. 돼지고기와 두부의 부드러운 식감과 함께 간장과 마늘의 풍부한 맛이 어우러져 맛있는 한 그릇 요리가 됩니다. 닭고기 알레르기가 없는 분들도 즐기기 좋은 요리이니 맛있게 즐겨보세요!\n"
     ]
    }
   ],
   "source": [
    "query = '돼 돼지고기 음식 먹어도 될까?'\n",
    "\n",
    "\n",
    "# Prompt\n",
    "template = '''\n",
    "find a recipe on https://www.10000recipe.com/ and you must explain the ingredients and the recipe.\n",
    "If there are any allergies, exclude the ingredients that cause the allergies.\n",
    "For example, if there is a chicken allergy, you should provide a recipe for a dish that does not contain chicken.\n",
    "Provide the explanation in Korean.\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({'question':query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c34b5cd-dea0-47f6-98f4-c87ce80c6290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe:{'name':'볶음밥','ingredients':'올반새우볶음밥| 짜장소스| 김치볶음밥| 모짜렐라치즈| 햄에그볶음밥| 데미그라스소스| 식용유| 트리플치즈닭다리너겟| 슈퍼크런치치킨텐더','recipe':['1. 볶음밥을 만들기 위해 팬에 식용유를 두르고 볶음밥 재료를 넣어 볶아줍니다.','2. 각각의 볶음밥 재료를 잘 섞어가며 볶아줍니다.','3. 볶음밥이 익으면 그릇에 담아내어 모얈렐라치즈를 올려 녹인 후 곁들여 드시면 완성됩니다.']}\n"
     ]
    }
   ],
   "source": [
    "# Retrieval\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 20, 'fetch_k': 500,'lambda_mult': 0.1}\n",
    ")\n",
    "retriever2 = vectorstore2.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 1, 'fetch_k': 3 ,'lambda_mult': 0.01}\n",
    ")\n",
    "\n",
    "query = '닭 알레르기가 있어. 볶음밥 레시피 알려줘'\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs2 = retriever2.get_relevant_documents(query)\n",
    "ans =  \"\"\"‘recipe’:{‘name’:’’’insert here’’’,’ingredients’:’’’insert here’’’,’recipe’:[’’’insert here’’’]}\"\"\"\n",
    "\n",
    "# Prompt\n",
    "template = '''주어진 문맥에는 요리 이름과 재료가 있습니다.\n",
    "재료를 바탕으로 https://www.10000recipe.com/에서 레시피를 찾아 재료와 요리법을 설명해 주세요.\n",
    "알레르기가 있는 경우, 알레르기를 유발하는 재료를 제외하세요.\n",
    "예를 들어, 닭고기 알레르기가 있다면 닭고기가 들어가지 않은 요리법을 제공해야 합니다.\n",
    "그리고 닭고기와 비슷한 의미인 재료들도 빼야해.\n",
    "예를들어 치킨과 닭은 비슷한 의미야. \n",
    "\n",
    "설명을 한국어로 제공하세요.\n",
    "다음 문맥을 바탕으로 질문에 답하세요:\n",
    "{context1} {context2}\n",
    "\n",
    "질문: {question}\n",
    "답변 형식은 {ans}으로 해줘.\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({'context1': (format_docs(docs)),'context2': (format_docs(docs2)), 'question':query,'ans':ans})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e19573a-4aa9-4352-b18e-d93d30b19bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/simple.csv', 'row': 16119}, page_content=': 16119\\n요리명: 닭고기볶음\\n재료: [재료] 닭 1/2 마리| 양파 1/2개| 계란 2개| 청정원 카레여왕 1/2 분량'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 29231}, page_content=': 29231\\n요리명: 닭볶음탕\\n재료: [재료] 자세한 재료는 본문내용에서| 확인 해 보실 수 있습니다!'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 45119}, page_content=': 45119\\n요리명: 닭손질\\n재료: [재료] 닭'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 706}, page_content=': 706\\n요리명: 닭안심볶음\\n재료:'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 50413}, page_content=': 50413\\n요리명: 치킨\\n재료: [재료] 닭고기 300g| 소금 약간| 후추 약간| 식용유 500ml'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 167253}, page_content=': 167253\\n요리명: 물에씻으면안좋은재료\\n재료: [재료] 닭고기| 버섯| 소고기| 파스타면'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 79880}, page_content=': 79880\\n요리명: 닭모래집\\n재료: [필수재료] 닭모래집'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 99816}, page_content=': 99816\\n요리명: 치킨스테이크\\n재료: [재료] 하림자연실록IFF치킨스테이크| 파인애플| 야파| 파프리카| 피망| 새송이버섯| 버섯'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 133716}, page_content=': 133716\\n요리명: 닭튀김\\n재료: [재료] 야식이야 1봉지'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 74554}, page_content=': 74554\\n요리명: 삼계탕\\n재료: [재료] 목우촌 닭고기 9호 1마리| 찹쌀 2컵| 통마늘 4~5개| 대추 6~7개| 약재 약간| 후추 약간| 소금 약간'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 336}, page_content=': 336\\n요리명: 닭고기조림\\n재료:'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 23931}, page_content=': 23931\\n요리명: 딸기쨈양념치킨\\n재료: [재료] 닭한마리| 밀가루| 쌀가루 [양념] 딸기쨈| 마늘| 간장| 고추장| 케찹| 소주(or청주)| 후추| 밀가루| 쌀가루| 소금'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 126308}, page_content=': 126308\\n요리명: 닭고기\\n재료: [재료] 처음요리 미음용 밀키트 1개'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 161312}, page_content=': 161312\\n요리명: 불닭크림파스타\\n재료: [재료] 치킨| 팽이버섯| 파스타면| 크림파스타소스| 불닭소스| 파슬리가루'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 130712}, page_content=': 130712\\n요리명: 에어프라이후라이드치킨\\n재료: [재료] 닭(닭볶음탕용)| 치킨가루| 우유| 식용유'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 28599}, page_content=': 28599\\n요리명: 치킨마요덮밥\\n재료: [재료] 먹다남은치킨| 계란| 김 [양념] 마요네즈| 데리야끼소스'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 53927}, page_content=': 53927\\n요리명: 닭\\n재료: [재료] 레시피마다 달라요~'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 44217}, page_content=': 44217\\n요리명: 볶음밥\\n재료: [재료] 닭볶음탕남은거 약간| 찬밥 1공기| 상추 약간| 소금김 약간| 체다치즈 1장'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 154347}, page_content=': 154347\\n요리명: 매운후라이드치킨\\n재료: [재료] 닭다리 9개| 마늘소금| 후추| 치킨튀김가루| 카레가루| 다진청양고추| 포도씨유'),\n",
       " Document(metadata={'source': 'data/simple.csv', 'row': 154845}, page_content=': 154845\\n요리명: 치킨까스\\n재료: [재료] 닭가슴살 3덩이| 계란 1개| 매운 카레가루 3스푼| 빵가루 5스푼| 소금 약간| 후추 약간| 식용유 3스푼')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a256a24-d297-49b6-8c84-fa7b532d46b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/교차반응식품.csv', 'row': 3}, page_content='알레르기식품: 닭고기')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839676d8-1a98-47c8-8e9b-b1520386332a",
   "metadata": {},
   "source": [
    "## 웹로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8ae230a1-ddf3-452f-8430-3f16948f841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### `웹로더`\n",
    "import bs4\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "url = \"https://www.10000recipe.com/recipe/394337\"\n",
    "\n",
    "# url다음에 ,안했다고 오류 났음...!!!!!!!!!!!!\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"view2_summary_in\", \"ready_ingre3\",\"view_step\"),\n",
    "            id=('recipeIntro','divConfirmedMaterialArea','obx_recipe_step_start',)\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "07735945-1ad4-482e-a458-5eff78ec4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "len(docs)\n",
    "\n",
    "text_splitter3 = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=38,\n",
    "    chunk_overlap=3,\n",
    "    encoding_name='cl100k_base'\n",
    ")\n",
    "\n",
    "documents3 = text_splitter3.split_documents(docs)\n",
    "len(documents3)\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model3 = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sbert-nli',\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")\n",
    "\n",
    "vectorstore3 = FAISS.from_documents(documents3,\n",
    "                                   embedding = embeddings_model3,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE  \n",
    "                                  )\n",
    "\n",
    "# # save db\n",
    "# vectorstore.save_local('./db/faiss')\n",
    "\n",
    "# import faiss\n",
    "# # load db\n",
    "# vectorstore = FAISS.load_local('./db/faiss', embeddings_model,\n",
    "#                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cd1eb976-e2e5-4cd4-89c3-d663d3b514ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "닭강정 관련 상품의 레시피:\n",
      "\n",
      "재료:\n",
      "- 닭가슴살\n",
      "- 밀가루\n",
      "- 식용유\n",
      "- 간장\n",
      "- 설탕\n",
      "- 다진 마늘\n",
      "- 다진 생강\n",
      "- 후추\n",
      "- 참기름\n",
      "- 깨\n",
      "\n",
      "레시피:\n",
      "1. 닭가슴살을 손질하여 한 입 크기로 잘라줍니다.\n",
      "2. 밀가루에 닭가슴살을 묻혀 튀김옷을 입혀줍니다.\n",
      "3. 식용유를 예열한 후 닭가슴살을 튀겨줍니다.\n",
      "4. 간장, 설탕, 다진 마늘, 다진 생강, 후추를 넣고 닭가슴살을 볶아줍니다.\n",
      "5. 참기름과 깨를 뿌려 완성합니다.\n",
      "\n",
      "이 레시피는 닭가슴살을 사용하므로 만약 닭고기 알레르기가 있는 경우 다른 고기나 해산물을 대체하여 레시피를 준비할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# Retrieval\n",
    "\n",
    "# 웹로더\n",
    "retriever3 = vectorstore3.as_retriever(\n",
    "    search_type='mmr',\n",
    "    search_kwargs={'k': 1, 'fetch_k': 3 ,'lambda_mult': 0.01}\n",
    ")\n",
    "\n",
    "\n",
    "query = '닭강정 레시피 알려줘'\n",
    "docs3 = retriever3.get_relevant_documents(query)\n",
    "\n",
    "# Prompt\n",
    "template = '''In the site, there are the name of a dish and its ingredients.\n",
    "Based on the ingredients,\n",
    "find a recipe on {site} and you must explain the ingredients and the recipe.\n",
    "If there are any allergies, exclude the ingredients that cause the allergies.\n",
    "For example, if there is a chicken allergy, you should provide a recipe for a dish that does not contain chicken.\n",
    "Provide the explanation in Korean.\n",
    "\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125',\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({'site': (format_docs(docs3)), 'question':query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a5228a0d-13bd-47a1-9acc-3a7a72776bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.10000recipe.com/recipe/394337'}, page_content='\\n                안녕하세요~ 오늘은 닭가슴살을 살짝튀겨서 양념에 졸인 닭강정입니다. 닭강정의 참맛은 적당히 졸여야하는 것이지만 저는 살짝 졸여서 바삭한 식감도 살렸더니 다들 좋아하더군요.                \\n\\n[재료]\\n\\n\\n\\n                                                                닭다리나 닭안심                                                                                                            \\n\\n400g \\n구매\\n\\n\\n\\n\\n                                                                치킨튀김가루                                                                                                            \\n\\n \\n구매\\n\\n\\n\\n\\n                                                                땅콩가루                                                                                                            \\n\\n \\n구매\\n\\n\\n\\n\\n                                                                소금                                                                                                            \\n\\n약간 \\n구매\\n\\n\\n\\n\\n                                                                후추                                                                                                            \\n\\n약간 \\n구매\\n\\n\\n\\n[양념]\\n\\n\\n\\n                                                                간장                                                                                                            \\n\\n1/2큰술 \\n구매\\n\\n\\n\\n\\n                                                                고추장                                                                                                            \\n\\n1큰술 \\n구매\\n\\n\\n\\n\\n                                                                케찹                                                                                                            \\n\\n2큰술 \\n구매\\n\\n\\n\\n\\n                                                                설탕                                                                                                            \\n\\n2큰술 \\n구매\\n\\n\\n\\n\\n                                                                꿀                                                                                                            \\n\\n2큰술 \\n구매\\n\\n\\n\\n\\n                                                                다진 마늘                                                                                                            \\n\\n1/2큰술 \\n구매\\n\\n\\n\\n\\n                                                                다진 생강                                                                                                            \\n\\n1/2큰술 \\n구매\\n\\n\\n\\n\\n                                                                다진 양파                                                                                                            \\n\\n1/2큰술 \\n구매\\n\\n\\n\\n\\n조리순서Steps\\n\\n\\n\\n\\n원본보기\\n\\n\\n닭은 한입 크기로 썰어 흐르는 물에 잘 씻어서 우유에 재워 비린내 제거 후 다시 씻어내어 물기를 꼭 짠 후에 소금 후추로 간을 해줍니다.치킨 튀김가루를 넣고 30분~1시간 정도 재워둡니다.180도 정도 되는 기름에 노릇하게 튀겨냅니다.양념은 분량대로 넣고 잘 섞어준 후 팬에 넣고 살짝 바글바글 하면 그때 튀긴 닭고기를 넣고 잘 섞어줍니다.\\n\\n\\n\\n\\n\\n\\n닭강정 관련 상품\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n애슐리 통살치킨1+닭강정1 / 양념반 후라이드반\\n\\n\\n16,990원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[로켓프레시] 멕시카나 매콤달콤 닭강정 (냉동)\\n\\n\\n7,640원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n멕시카나 마늘간장 닭강정 (냉동)\\n\\n\\n7,640원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n푸라닭 달콤순살강정 (냉동), 500g, 1개, 500g\\n\\n\\n9,900원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[로켓프레시] 매콤달콤 바삭 닭강정 (냉동)\\n\\n\\n12,800원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n닭강정 치킨박스 소 맛있닭, 1개, 200개입\\n\\n\\n34,740원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n로만 닭강정\\n\\n\\n10,450원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n등록일 : 2008-01-03 수정일 : 2016-08-16 \\n저작자의 사전 동의 없이 이미지 및 문구의 무단 도용 및 복제를 금합니다.\\n\\n')]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9f235-6598-4271-81cd-d6e3c73ec60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 입력을 그대로 받는\n",
    "from langchain.schema.runnable import RunnablePassthrough "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
